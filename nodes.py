import os
import sys
import torch
import numpy as np
from PIL import Image, ImageFilter, ImageEnhance, ImageOps
import folder_paths
import types
import traceback

# å­˜å‚¨æŠ¥é”™ä¿¡æ¯
LOAD_ERROR_TRACEBACK = None

# --- 1. è‡ªåŠ¨å¯»è·¯é€»è¾‘ ---
current_node_path = os.path.dirname(os.path.abspath(__file__))
fashn_lib_parent = None

for root, dirs, files in os.walk(current_node_path):
    if "fashn_vton" in dirs:
        if os.path.exists(os.path.join(root, "fashn_vton", "__init__.py")):
            fashn_lib_parent = root
            break

if fashn_lib_parent:
    if fashn_lib_parent not in sys.path:
        sys.path.insert(0, fashn_lib_parent)
else:
    LOAD_ERROR_TRACEBACK = f"âŒ æ‰¾ä¸åˆ° 'fashn_vton' æ–‡ä»¶å¤¹ï¼\nè¯·æ£€æŸ¥ src è§£å‹ä½ç½®ã€‚"

# --- 2. æ ¸å¿ƒåŠ è½½é€»è¾‘ ---
TryOnPipeline = None

if not LOAD_ERROR_TRACEBACK:
    try:
        try:
            import fashn_human_parser
        except ImportError:
            raise ImportError("ç¼ºå°‘ä¾èµ–åº“: fashn-human-parser")

        import fashn_vton
        
        # è·¯å¾„è¡¥ä¸
        if not hasattr(fashn_vton, "src"):
            mock_src = types.ModuleType("fashn_vton.src")
            fashn_vton.src = mock_src
            sys.modules["fashn_vton.src"] = mock_src
            fashn_vton.src.fashn_vton = fashn_vton
            sys.modules["fashn_vton.src.fashn_vton"] = fashn_vton

        from fashn_vton import TryOnPipeline

    except Exception as e:
        LOAD_ERROR_TRACEBACK = traceback.format_exc()
        TryOnPipeline = None

# --- 3. è¾…åŠ©å‡½æ•° ---
def tensor2pil(image):
    return Image.fromarray(np.clip(255. * image.cpu().numpy().squeeze(), 0, 255).astype(np.uint8)).convert("RGB")

def pil2tensor(image):
    return torch.from_numpy(np.array(image).astype(np.float32) / 255.0).unsqueeze(0)

# --- 4. èŠ‚ç‚¹å®šä¹‰ ---
class FashnVTON_Loader:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        base_model_path = os.path.join(folder_paths.models_dir, "fashn_vton")
        return {
            "required": {
                "model_dir": ("STRING", {"default": base_model_path, "multiline": False}),
            }
        }

    RETURN_TYPES = ("FASHN_PIPE",)
    RETURN_NAMES = ("pipeline",)
    FUNCTION = "load_model"
    CATEGORY = "Fashn-VTON"

    def load_model(self, model_dir=None):
        if TryOnPipeline is None:
            if LOAD_ERROR_TRACEBACK:
                raise ImportError(f"\n{'='*20} æ’ä»¶åŠ è½½å¤±è´¥ {'='*20}\n\n{LOAD_ERROR_TRACEBACK}\n{'='*50}")
            else:
                raise ImportError("æœªçŸ¥é”™è¯¯ï¼šTryOnPipeline æœªåˆå§‹åŒ–ã€‚")

        if not model_dir:
            model_dir = os.path.join(folder_paths.models_dir, "fashn_vton")

        if not os.path.exists(model_dir):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶å¤¹: {model_dir}")
        
        safetensor = os.path.join(model_dir, "model.safetensors")
        if not os.path.exists(safetensor):
             raise FileNotFoundError(f"ç¼ºå°‘ model.safetensors: {model_dir}")
        
        try:
            pipeline = TryOnPipeline(weights_dir=model_dir)
            return (pipeline,)
        except Exception as e:
            raise Exception(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥:\n{traceback.format_exc()}")

class FashnVTON_Run:
    CATEGORY_MAP = {
        "tops (ä¸Šè¡£/å¤–å¥—)": "tops",
        "bottoms (ä¸‹è£…/è£¤è£™)": "bottoms",
        "one-pieces (å…¨èº«/è¿è¡£è£™)": "one-pieces"
    }
    
    GARMENT_TYPE_MAP = {
        "model (æ¨¡ç‰¹èº«ä¸Šçš„è¡£æœ)": "model",
        "flat-lay (å¹³é“º/æŒ‚æ‹çš„è¡£æœ)": "flat-lay",
    }
    
    RESIZE_MODE_MAP = {
        "Bilinear (æŸ”å’Œ/æŠ—é”¯é½¿)": Image.Resampling.BILINEAR,
        "Bicubic (æ ‡å‡†)": Image.Resampling.BICUBIC,
        "Lanczos (é”åˆ©)": Image.Resampling.LANCZOS,
        "Nearest (ç¡¬è¾¹ç¼˜/æ— ç™½è¾¹)": Image.Resampling.NEAREST, # æ–°å¢
    }

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "pipeline": ("FASHN_PIPE",),
                "person_image": ("IMAGE",),
                "garment_image": ("IMAGE",),
                
                "category": (list(cls.CATEGORY_MAP.keys()), {"default": "tops (ä¸Šè¡£/å¤–å¥—)"}),
                "garment_type": (list(cls.GARMENT_TYPE_MAP.keys()), {"default": "model (æ¨¡ç‰¹èº«ä¸Šçš„è¡£æœ)"}),
                "num_timesteps": ("INT", {"default": 50, "min": 10, "max": 100, "step": 1, "label": "é‡‡æ ·æ­¥æ•°(Steps)"}),
                "guidance_scale": ("FLOAT", {"default": 2.5, "min": 1.0, "max": 20.0, "step": 0.1}),
                "seed": ("INT", {"default": 42, "min": 0, "max": 0xffffffffffffffff}),
                "segmentation_free": ("BOOLEAN", {"default": False, "label": "æ— åˆ†å‰²æ¨¡å¼(Seg Free)"}),
            },
            "optional": {
                "restore_original_size": ("BOOLEAN", {"default": True, "label": "å¼ºåˆ¶è¿˜åŸåŸå›¾å°ºå¯¸"}),
                "resize_method": (list(cls.RESIZE_MODE_MAP.keys()), {"default": "Bilinear (æŸ”å’Œ/æŠ—é”¯é½¿)"}),
                
                # --- V13 å†…è¡£ä¸“ç”¨å‚æ•° ---
                "smart_erode": ("INT", {"default": 0, "min": 0, "max": 5, "step": 1, "label": "æ™ºèƒ½ç¼©è¾¹(å»é™¤ç™½è¾¹)"}),
                "texture_boost": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 5.0, "step": 0.1, "label": "è•¾ä¸/çº¹ç†å¢å¼º(USM)"}),
            }
        }

    RETURN_TYPES = ("IMAGE",) 
    RETURN_NAMES = ("image",)
    FUNCTION = "run_inference"
    CATEGORY = "Fashn-VTON"

    def run_inference(self, pipeline, person_image, garment_image, category, garment_type, num_timesteps, guidance_scale, seed, segmentation_free=False, restore_original_size=True, resize_method="Bilinear (æŸ”å’Œ/æŠ—é”¯é½¿)", smart_erode=0, texture_boost=0.0):
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed(seed)
            
        if person_image is None or garment_image is None:
            raise ValueError("è¾“å…¥å›¾ç‰‡ä¸èƒ½ä¸ºç©º")

        real_category = self.CATEGORY_MAP.get(category, "tops")
        real_garment_type = self.GARMENT_TYPE_MAP.get(garment_type, "model")
        resample_mode = self.RESIZE_MODE_MAP.get(resize_method, Image.Resampling.BILINEAR)

        print(f"ğŸš€ [Fashn-VTON] å¼€å§‹ç”Ÿæˆå†…è¡£ä¼˜åŒ–ç‰ˆ...")
        print(f"   Mode: {real_category} | Erode: {smart_erode} | Texture: {texture_boost}")

        person_pil = tensor2pil(person_image)
        garment_pil = tensor2pil(garment_image)
        original_size = person_pil.size

        try:
            result = pipeline(
                person_image=person_pil,
                garment_image=garment_pil,
                category=real_category,
                garment_photo_type=real_garment_type,
                num_timesteps=num_timesteps, 
                guidance_scale=guidance_scale,
                segmentation_free=segmentation_free,
                num_samples=1,
            )
            output_image = result.images[0]

        except TypeError:
            print(f"âš ï¸ [Fashn-VTON] é™çº§å…¼å®¹...")
            result = pipeline(
                person_image=person_pil,
                garment_image=garment_pil,
                category=real_category,
                num_inference_steps=num_timesteps,
                guidance_scale=guidance_scale
            )
            output_image = result.images[0]
        except Exception as e:
            raise Exception(f"æ¨ç†å¤±è´¥:\n{traceback.format_exc()}")

        # --- åå¤„ç†ï¼šå†…è¡£/è•¾ä¸ ä¸“é¡¹ä¼˜åŒ– ---
        
        # 1. æ™ºèƒ½ç¼©è¾¹ (Smart Erode) - åœ¨å°å›¾é˜¶æ®µå¤„ç†æ•ˆæœæœ€å¥½
        # è¿™æ­¥æ˜¯ç‰©ç†å»é™¤â€œç™½è¾¹â€çš„å…³é”®ï¼Œé€šè¿‡æœ€å°å€¼æ»¤æ³¢è®©é»‘è‰²çº¿æ¡å˜ç²—ï¼Œåƒæ‰ç™½è¾¹
        if smart_erode > 0:
            # åªæœ‰åœ¨å¤„ç†æ·±è‰²è•¾ä¸/æµ…è‰²èƒŒæ™¯æ—¶å¼€å¯æ•ˆæœæœ€å¥½
            # ä½¿ç”¨ MinFilter æ¨¡æ‹Ÿè…èš€æ•ˆæœ
            output_image = output_image.filter(ImageFilter.MinFilter(1)) 
            if smart_erode > 1:
                 # å¦‚æœè¿˜éœ€è¦æ›´å¼ºï¼Œå†å¤šè…èš€ä¸€æ¬¡ï¼Œä½†é€šå¸¸1æ¬¡å¤Ÿäº†
                 pass

        if restore_original_size and output_image.size != original_size:
            print(f"â†”ï¸ [Fashn-VTON] è¿˜åŸå°ºå¯¸...")
            output_image = output_image.resize(original_size, resample_mode)
            
            # 2. çº¹ç†å¢å¼º (Texture Boost / USM) - åœ¨å¤§å›¾é˜¶æ®µå¤„ç†
            # ä¸“é—¨é’ˆå¯¹è•¾ä¸æ¨¡ç³Šçš„é—®é¢˜ï¼Œä½¿ç”¨ USM é”åŒ–æå–é«˜é¢‘ç»†èŠ‚
            if texture_boost > 0:
                # åŠå¾„ radius=2 æ˜¯é’ˆå¯¹ 4K å›¾ä¼˜åŒ–çš„
                # Percent æ˜¯å¼ºåº¦
                print(f"âœ¨ [Fashn-VTON] åº”ç”¨è•¾ä¸å¢å¼º...")
                output_image = output_image.filter(ImageFilter.UnsharpMask(radius=2, percent=int(texture_boost * 50), threshold=3))

        return (pil2tensor(output_image),)

# --- æ³¨å†Œ ---
NODE_CLASS_MAPPINGS = {
    "FashnVTON_Loader": FashnVTON_Loader,
    "FashnVTON_Run": FashnVTON_Run
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "FashnVTON_Loader": "ğŸ‘• Fashn VTON Loader v1.5",
    "FashnVTON_Run": "ğŸ‘— Fashn VTON Run-zyp (Lingerie)"
}